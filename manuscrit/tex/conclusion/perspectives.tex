\section{Perspectives de recherches}\label{sec:conclusion:perspectives}
Avec l'avènement des mouvements tels que le \textit{BigData} ou l'\textit{Internet des objets}, la gestion des données a subi un renouveau depuis quelques années. Nous avons pu apporter notre contribution toutefois, il reste de nombreux défis scientifiques à relever en continuité de notre travail. Nous avons identifié quatre pans de recherches à explorer sur le court et long terme.

\subsection{De la représentation des données d'un système}
Dans notre analyse de l'état de l'art, nous avons vu que peu d'approches permettaient de \textit{modéliser} un ensemble de flux de données. Dans le chapitre~\ref{chap:contrib:asteroid}, nous avons présenté le schéma physique d'Asteroid. Ce schéma est découpé en deux sections. Tout d'abord, le schéma descriptif représentant par un schéma normalisé le modèle du système. Ensuite, le schéma historique permet d'archiver une liste d'historiques. Cette approche est avant tout dirigée par l'implémentation.

En effet, cette modélisation nous permet d'ajouter des historiques de flux à volonté, toutefois, le lien entre les flux et les concepts est établi par un unique identifiant. De façon similaire, nous avons considéré que les flux de données étaient des flux indépendants, sans liens entre eux a priori.

Or, dans la conception d'une base de données, le développeur identifie ses données, établit des dépendances fonctionnelles, et construit un schéma respectant ces dépendances (entité relation ou modèle \textit{UML}). Dans notre cas, nous n'avons pu opérer de la sorte pour deux raisons : (1) la notion de dépendance fonctionnelle n'a pas été définie pour les flux (2) nous ne concevons pas les sources de données, nous subissons ce que le système nous fournit.

Dans Asteroid, nous avons séparé la gestion des données volatiles de la description du système. Cette séparation s'est faite à cause des dynamiques différentes. Est-il toutefois possible de créer une modélisation pour gérer nativement ces classes de dynamiques ? Il serait ainsi possible d'intégrer des sources ayant des classes de dynamiques conflictuelles. Par exemple, une donnée de lieu peut être statique sur certains objets et volatile sur d'autres. Cet exemple produirait un historique de flux et une entrée dans le schéma descriptif du système qu'il faudrait gérer à la main lors de l'interrogation du système.

En dehors des approches de base de données classiques, le domaine de la gestion de contexte, comme nous l'avons montré, fournit plusieurs outils pour effectuer des représentations de données hétérogènes. Être capable de formaliser un contexte uniforme permettrait d'utiliser notre approche dans des applications plus larges (\textit{context-aware softwares}, \textit{service level checking},...).

\subsection{De l'expressivité des langages de requêtes}
Astral est un langage algébrique capable d'interroger, de manière instantanée ou continue, des flux ou des relations (temporelles). Ce langage est très expressif et permet de manipuler de manière claire et déterministe nos entités comme nous l'avons démontré dans le chapitre~\ref{chap:validation:expressivite}.

Néanmoins, nous n'avons en l'état que très peu d'outils pour analyser l'expressivité d'un langage de requête dans le cadre des flux en dehors de la comparaison avec les outils actuels. Pour l'algèbre relationnelle, nous savons sa limitation grâce à la logique du premier ordre (en excluant la récursion). Dans le cas d'Astral, nous n'avons pas de moyens en l'état pour quantifier grâce à des opérateurs logiques la classe des résultats possibles.

Une fois cette expressivité connue, de la même façon que le \textit{SQL} a été défini pour l'algèbre relationnelle, nous pouvons établir un langage déclaratif aussi expressif qu'Astral. L'expression en termes déclaratifs permet aux experts métiers du système, non-spécialiste de la gestion de flux de données, de manipuler aisément les données. Sachant que nous sommes garantis d'une mise en œuvre efficace à partir de l'expression algébrique d'une requête, il nous faut désormais faciliter l'accès à ces capacités.

\subsection{De la performance de l'observation}
Nous avons présenté avec Astronef, dans le chapitre~\ref{chap:contrib:astronef}, une méthode générique, automatique et extensible pour évaluer de manière efficace les requêtes continues. Nous avons prouvé son efficacité dans le chapitre~\ref{chap:valid:perfs}. Toutefois, les limites de cette approche peuvent être rapidement atteintes. En effet, lorsque deux règles sont applicables, alors l'une est privilégiée à l'autre.

De même, lors de la jointure de plusieurs relations, l'optimisation de requête classique de SGBD a montré que l'approche par règle n'est pas suffisante. La recherche de solutions optimales par algorithmes de programmation dynamique permet en général la résolution de ce problème. Toutefois, il est nécessaire de prédire les tailles des relations. Ces approches sont difficiles et deviennent importantes lorsque les expressions de requêtes sont générées grâce à un langage déclaratif.

Afin d'envisager l'observation de plusieurs millions d'entités, il est nécessaire d'établir des solutions de stratégies globales. Nous avons établi dans cette thèse des règles capables de rendre l'évaluation d'\textbf{une} requête efficace. Dans le cadre où des centaines de requêtes sont établies sur plusieurs nœuds distribués, une optimisation locale ne suffit plus. Ainsi, il est nécessaire de concevoir des algorithmes de partage de requête et de calcul à l'exécution de nouveaux plans de requêtes distribués. Notre formalisation de l'équivalence de requête transposée nous permet de mettre en pratique le partage automatique de plan. Toutefois, de nouvelles approches sont à envisager pour pouvoir effectuer un passage à l'échelle des infrastructures de gestions de flux de données.

\subsection{De l'analyse et la compréhension d'un système}
Dans cette thèse, nous avons conçu une méthodologie générique pour gérer les données d'un système. Cette gestion avait pour but de mieux comprendre le système et éventuellement en cas de problème, de pouvoir le diagnostiquer. Nous avons pu mettre en pratique cette solution sur un problème en production chez \textit{Orange France}.

Il a été observé sur quelques centaines de \textit{Livebox} en France un problème récurrent de coupure de service VoIP pour raisons inconnues. Nous avons été contactés pour aider à la résolution de ce problème. Les experts métiers nous ont donné accès à l'ensemble des données de configuration de l'appareil (un accès \textit{pull} et un accès événementiel), soit environ 10~000 paramètres. Nous avons installé notre prototype sur le réseau d'une \textit{Livebox} présentant le problème pour tracer les événements ainsi que les changements des données de configuration, collectées toutes les deux minutes (minimum supportable).

Nous avons pu effectuer plusieurs analyses a posteriori grâce au stockage des données sur Asteroid. Nous n'avons toutefois pas pu résoudre le problème. Nous avons pu observer les conséquences du problème en remarquant que la VoIP devenait inactive. Toutefois, nous n'avons pas pu \textbf{comprendre} le problème, ni en trouver la \textbf{cause}. À cet échec nous pouvons conclure trois possibilités : notre approche n'est pas correcte, nous n'avons pas su traiter les données correctement ou les données qui nous auraient permis de conclure n'étaient pas accessibles. Nous ne pouvons répondre à de telles affirmations. Toutefois, nous avons pu exploiter les capacités que pouvaient nous fournir nos sources de données, ce qui a permis la compréhension d'autres phénomènes en dehors du problème en question.

La compréhension d'un système est un domaine à part entière. Ce domaine permet de fournir des méthodes et des outils, issus des analyses statistiques et des intelligences artificielles multiagents, pour mieux appréhender la complexité d'un système. Nous avons fourni un outil pour observer les données d'un système. Un croisement avec ces approches permettrait d'obtenir une vraie démarche de diagnostic.