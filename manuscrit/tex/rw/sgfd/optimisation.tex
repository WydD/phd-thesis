\section{Optimisations de l'évaluation de requêtes}\label{sec:rw:sgfd:optim}
L'héritage des connaissances du domaine des systèmes relationnels a été central sur la conception des systèmes de gestion de flux de données. Toutefois, dans le cadre des SGFD plusieurs aspects sont importants. En premier lieu, nous présentons les points spécifiques d'optimisation du traitement des flux. Enfin, nous détaillons les optimisations des algorithmes des opérateurs.

\subsection{Optimisation du traitement des flux}\label{sec:rw:sgfd:optimisation:flux}
L'infrastructure de traitement des flux présente des spécificités par rapport aux SGBD. Pour l'optimisation cela concerne : le mode de traitement des requêtes, la gestion de la charge sur le long terme, le partage des requêtes, l'ordonnancement et enfin le routage pour les infrastructures distribués. Nous pouvons remarquer que toutes ces aspects ont été explorées premièrement dans le domaine des systèmes de base de données. Toutefois, ils prennent plus d'ampleur dans ce contexte.

\subsubsection{Calcul incrémental}
Le calcul incrémental permet d'évaluer une requête continue grâce aux traitements effectués sur les changements des entités manipulées. Par exemple, pour une fenêtre glissante dont le changement est d'un seul n-uplet à chaque évaluation, il n'est peut-être pas nécessaire d'appliquer les traitements sur la relation complète. Comme présenté dans la section~\ref{sec:rw:sgfd:modeles}, historiquement, les premiers traitements de flux~\cite{Terry:tapestry} étaient considérés comme des traitements particuliers sur les n-uplets qui ont été ajoutés à une relation.

De façon plus générale, en se plaçant dans l'algèbre \textit{ACO} : Soit $R$ une relation, au lieu de calculer une requête sur $R(\tau)$, il est possible de considérer les \textit{delta} de cette relation : $\Delta_R^+(\tau) = R(\tau)-R(\tau-1)$ et $\Delta_R^-(\tau) = R(\tau-1)-R(\tau)$. Comme le traitement des fenêtres, par exemple, peut fournir directement ces différences : il n'y a pas de surcoût à l'utilisation d'un tel procédé. Comme la cardinalité des $\Delta$ est souvent minime face à celle de la relation totale. Il devient intéressant de travailler avec ces données.

\subsubsection{Multi-Query Optimization (MQO)}
Aussi connu sous le nom de \textit{Global Query Optimization}, cette optimisation profite des exécutions parrallèles pour éviter la redondances de traitement et une économie de ressources. Elle est issue du monde des SGBD~\cite{Sellis:mqo} et permet de répondre à plusieurs requêtes en même temps en utilisant des parties communes (classiquement, lorsque seules les clauses de sélection sont différentes). L'idée est toutefois peu exploitée dans les SGBD car il faut pouvoir soumettre plusieurs requêtes en même temps et les gestions de caches ont permis de faire de bons résultats pour ce genre de requêtes.

Dans le monde des flux de données, cette optimisation est largement reconnue comme importante. Les requêtes durent dans le temps, potentiellement indéfiniment. Le nombre de requêtes similaires peut être important. Ainsi, partager les ressources des requêtes devient un enjeu. Plusieurs points interviennent ici.
\begin{itemize}
 \item Tout d'abord l'existence des \textit{m-op} (multi-operators)~\cite{Hong:mqo}. Ces opérateurs permettent de regrouper plusieurs opérateurs en un seul permettant d'éviter des duplicatas de n-uplets. Un exemple classique est de grouper deux conditions de sélection sur un flux commun en une seule. Ainsi, si un n-uplet vérifie les deux conditions, un seul n-uplet est fournit avec l'indication qu'il appartient aux requêtes 1 et 2. Cette optimisation permet de faire des requêtes en utilisant les définitions de flux fragmentés.
 \item Grande disponibilité des ressources. Chaque opérateur utilise des ressources et peut potentiellement les partager avec d'autres. Cependant, ces ressources ne sont peut-être pas utiles à partager car elles sont trop précises. Dans plusieurs travaux~\cite{Arasu:resource}, le calcul des agrégations sur fenêtres peut être partagé. En découpant la mémoire par bloc de façon adaptée, il est possible de partager les ressources afin d'économiser la mémoire.
\end{itemize}

Les propositions de partage de plans de requêtes sont des solutions actuellement manuelles au déploiement de la requête. Seuls des travaux comme RUMOR~\cite{Hong:mqo} recherchent à fusionner le nouveau plan de requête avec un autre (sous conditions encore très strictes). Un problème ouvert reste de savoir si les optimisations locales (optimisation algébrique) gênent les optimisations globales. Une requête est optimisé au début de son traitement mais la stratégie d'exécution peut être modifiée pendant son évaluation. En effet, si une nouvelle requête arrive et qu'en changeant légèrement la structure de la première, il est possible d'obtenir un partage, alors il est probable que ce nouveau plan soit le préféré. Ainsi, l'adaptabilité de l'exécution d'une requête est importante.

\subsubsection{Parallélisation \& Ordonnancement}
Comme les requêtes peuvent être exécutées en parallèle, leur ordonnancement est important. Afin d'éviter les engorgements, ou pour donner plus de priorité à une partie de la requête, l'ordonnanceur doit cadancer les unités de traitement pour fournir des résultats conformes à la qualité attendue. Par exemple, une requête importante d'alerte peut exprimer des contraintes forte de \textit{latence}, contrairement à une requête d'observation passive. Le problème est que l'exécution d'une requête dans le cadre d'un SGFD n'est pas triviale, comme présenté est section~\ref{sec:rw:sgfd:infra}. Ceci implique que la gestion des contraintes d'ordonnancement sont plus complexes à mettre en œuvre. Plusieurs stratégies ont été proposés~\cite{Babcock:chain, Jiang:scheduling} afin de garantir le meilleur temps de réponse en utilisant le moins de resources possibles.

\subsubsection{Placement des opérateurs \& Routage}
Le placement des opérateurs est important dans le cadre de l'évaluation distribuée d'une requête. Dans le cadre des topologies de réseaux complexes cet aspect implique aussi des problèmes de routages. Pour le traitement en flux de grandes quantités de données, des optimisations de routage rentrent en compte sur le calcul de jointure par exemple~\cite{Zhou:pmjoin, Palma:p2p}. En effet, pour optimiser le plan de requête, il faut savoir s'il vaut mieux effectuer une opération lourde répartie sur plusieurs nœuds, avec des surcoûts de communication, ou centralisé mais plus lourd en traitement. Dans le cadre des réseaux de capteurs, le coût d'un plan de requête (notamment énergétique) est analysé afin de fournir un routage efficace au moment du déploiement~\cite{Galpin:snee} ou à l'exécution~\cite{Madden:tinydb}.

Nous avons vu les optimisations spécifiques au traitement des requêtes dans le cadre de la gestion de flux. Nous détaillons maintenant les optimisations algorithmiques des opérateurs.

\subsection{Optimisation des opérateurs}
Tout comme dans les SGBD, les SGFD possèdent plusieurs implémentations et plusieurs algorithmes pour calculer des opérateurs. Nous détaillons dans cette section deux opérations qui ont reçu l'attention de la communauté : la jointure et l'opérateur d'agrégation sur fenêtre.

\subsubsection{Jointures}
Comme présenté précédemment, la jointure en flux n'est pas aussi simple qu'une jointure de relations car elle nécessite la gestion de fenêtres. Beaucoup de travaux~\cite{Han:join, Srivastava:join, Law:join} se sont portés sur les jointures similaires à $I_S (S_1[W_1] \Join ... \Join S_n[W_n])$ et bien souvent limités par $W_1=...=W_n$. L'implémentation de ceci requiert a priori une quantité non bornée de mémoire. De plus le traitement d'un n-uplet peut nécessiter beaucoup du temps si les cardinalités sont grandes ce qui peut entrainer des congestions. Les travaux se concentrent sur des résultats approximatifs en établissant des modèles statistiques inspirés du \textit{load-shedding} sur les attributs de jointures.

L'utilisation d'index, comme dans les SGBD, est désormais plus délicate car les données sont constamment actualisées. Le point crucial de l'index est que le surcoût introduit au moment de l'insertion d'une donnée est amorti par le nombre de fois où la donnée est interrogée. Si les relations sont constamment mises à jour, ce surcoût a plus de difficultées à être amorti. Il est toutefois important de noter que les optimisations présentes dans le calcul de jointures relationnelles en mode \textit{pipeline}~\cite{Gajski:pipeline} telles que le \textit{symetric hash join}~\cite{Wilschut:symetricjoin} sont applicables aux requêtes continues. En effet, le mode \textit{pipeline} est similaire au calcul incrémental dans le cadre des SGFD.

\subsubsection{Fenêtrage et agrégations}\label{sec:rw:sgfd:optim:fenetres}
Nous nous intéressons maintenant particulièrement aux traitements de requêtes d'agrégations de classe $I_S(G(S[W]))$. Les travaux les plus conséquents se focalisent sur le calcule approximatif des opérations de comptage et de quantile en mémoire limité~\cite{Arasu:window}. Ce comptage permet d'effectuer les autres statistiques en quantité restreinte~\cite{Datar:stats}, comme par exemple : minimums, maximums, sommes, moyennes, histogrammes et nombre de valeurs distinctes. L'approche est principalement mathématique et probabiliste. Par exemple, en se fixant une tolérance $\eps$, il est possible d'obtenir un résultat dans une quantité de mémoire prévisible. 

L'évaluation exacte et efficace de ces opérations reste possible grâce à l'utilisation de \textit{Pane}~\cite{Li:pane}. Le principe est qu'une fenêtre sur 4 minutes décalée de 1 minute peut être vue comme 4 blocs de 1 minutes. Ces blocs peuvent être agrégés. Ainsi, lors du décalage de la fenêtre, il devient possible de réutiliser les résultats de chacun de ces blocs pour calculer le résultat de la fenêtre entière. Afin de faire ces opérations, il est nécessaire de catégoriser les fonctions agrégations. 

Les agrégats \textit{holistiques} sont définis par deux fonctions $L$ et $S$. Le calcul d'un tel agrégat $F$ sur un ensemble $X$ partitionnés en blocs $(X_n)$ est fait par : $$F(X) = S(\{L(X_i), i\in \N\}).$$ 
Dans ce cas, il devient évident que le calcul de l'agrégat sur les fenêtres est fait par l'application de la fonction $S$ sur les évaluations des blocs par $L$. Par exemple, l'agrégation \textit{max} est \textit{holistique} car les définitions $L=S=\max$ permettent ce calcul.

Les \textit{différentiables} sont elles définies par trois fonctions $H$, $J$ et $L$ permettant la suppression et l'ajout de données dans l'agrégat : $$\begin{cases} F(X-Y) \ =& H(L(Y), L(X)) \\ F(X\cup Y)\ =& J(L(Y), L(X))\end{cases}$$
Par exemple, le comptage et la moyenne sont des agrégats \textit{différentiables}. Le comptage peut être fait avec $L=$ \textit{count}, $H=-$ et $J=+$. Son application dans le cadre de l'évaluation de fenêtres est comme suit : reprise du résultat de la fenêtre précédente, soustraction du bloc qui a été enlevé de la fenêtre et ajout du nouveau bloc.
